# -*- coding: utf-8 -*-
"""efficientdet_test

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zJecFSL_tj7FwVODYRiyHsXkyoQCNkAJ
"""

import sys
sys.path.insert(0, "../input/timmefficienctdetpytorchstable/archive")
sys.path.insert(0, "../input/omegaconf")
import torch.nn.functional as F
import traceback
from torch import optim
from effdet import *
from effdet.efficientdet import HeadNet
from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain
from effdet.anchors import Anchors, AnchorLabeler, generate_detections, MAX_DETECTION_POINTS
from effdet.loss import DetectionLoss

class covid_Dataset(Dataset):

    def __init__(self,data,train=True,transform=None):
        self.df = data
        self.train = train
        self.transform = transform
    def __getitem__(self,index):

        patient_id, study, box_count, category, sex, body_part, rows, columns, _, _, _, _, xmin, ymin, xmax, ymax,label = self.df.iloc[index].values
        img = cv2.imread('/kaggle/input/equalhist/test_equalhist/'+patient_id+'.jpg')
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)
        img = img/255.0
        shape = img.shape
        width = shape[0]
        height = shape[1]
        if self.transforms:
            sample = {'image':img}
            sample = self.transforms(**sample)
            image = sample['image']
                    
        return img, width, height,image_id
    def __len__(self):
        return len(self.df)

if __name__ == '__main__':
    # -------------- hyper parameter --------------
    batch_size = 16
    learning_rate = 0.0005
    model_name = 'efficientdet_model'
    # ------------------------------------------
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    test_transform = A.Compose(
    [   A.Resize(256,256),
        ToTensorV2()])
    test_set = covid_Dataset("./png/test.xlsx",False,transform = test_transform)
    test_loader = DataLoader(test_set,batch_size=1)
    model.load_state_dict(torch.load('../input/aaaaaaa/weights.pth'))
    model = model.to(device)
    model = EfficientDetTrainer(model, config, device)
    model.eval()
    box_detections =[]
    for step_, (batch) in enumerate(loader):
        images = list(image.to(device) for image in batch[0])
        targets = [{k: v.to(device) for k, v in t.items()} for t in batch[1]]
        boxes = [t['boxes'].float() for t in targets]
        classes = [t['labels'].float() for t in targets]
        inputs = torch.stack(images)
        loss_dict,output = trainer(inputs,boxes,classes)

a = torch.load('../input/aaaaaaa/weights.pth')
model.load_state_dict(a)
model = model.to(device)
model = DetBenchEvalMB(model,config,device)
model.eval()

tk0 = tqdm(data_loader_test, desc="Iteration")
box_detections = []

for batch_idx, (input, image_file, study_file, width, height,dummy,img) in enumerate(tk0):
    input = [i.to(device) for i in input]
    dummy = [d.to(device) for d in dummy]
    input = torch.stack(input)
    output = model(input,dummy)
    output = post_process_outputs(output,width,height)
    output = output.cpu().detach().numpy()
    for q in range(0,output.shape[0]):
        boxes_string = ''
        for b in range(0,output.shape[1]):
            if output[q,b,4] > 0.1:  
                boxes_string = boxes_string + 'opacity ' + str (output[q,b,4]) + ' ' + str(int(output[q,b,0])) + ' ' + str(int(output[q,b,1])) + ' ' + str(int(output[q,b,2])) + ' ' + str(int(output[q,b,3])) + ' '
        boxes_string = boxes_string + 'opacity ' + str (scores[q,b]) + ' ' + str(int(output[q,b,0])) + ' ' + str(int(output[q,b,1])) + ' ' + str(int(output[q,b,2])) + ' ' + str(int(output[q,b,3])) + ' '
        if len(boxes_string) == 0:
            boxes_string = 'none 1 0 0 1 1 '
        boxes_string = boxes_string[:len(boxes_string)-1]
        box_string_rec = [image_file[q], boxes_string]
        box_detections.append(box_string_rec)
  
df_box_detections = pd.DataFrame(box_detections,columns=['id', 'PredictionString'])
df_box_detections.to_csv('/kaggle/working/submission.csv',index = False)